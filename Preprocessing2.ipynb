{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Preprocessing2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FyxXPgu93k5v"
      },
      "outputs": [],
      "source": [
        "!pip install indic-nlp-library\n",
        "\n",
        "import pandas as pd\n",
        "import re\n",
        "from indicnlp.tokenize import indic_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emoji_pattern = re.compile(\"[\"u\"U0001F600-U0001F64F\"  # emoticons\n",
        "        u\"U0001F300-U0001F5FF\"  # symbols & pictographs\n",
        "        u\"U0001F680-U0001F6FF\"  # transport & map symbols\n",
        "        u\"U0001F1E0-U0001F1FF\"  # flags (iOS)\n",
        "        u\"U00002500-U00002BEF\"  # chinese char\n",
        "        u\"U00002702-U000027B0\"\n",
        "        u\"U00002702-U000027B0\"\n",
        "        u\"U000024C2-U0001F251\"\n",
        "        u\"U0001f926-U0001f937\"\n",
        "        u\"U00010000-U0010ffff\"\n",
        "        u\"u2640-u2642\" \n",
        "        u\"u2600-u2B55\"\n",
        "        u\"u200d\"\n",
        "        u\"u23cf\"\n",
        "        u\"u23e9\"\n",
        "        u\"u231a\"\n",
        "        u\"ufe0f\"\n",
        "        u\"u3030\"\"]+\", flags=re.UNICODE)\n",
        "\n",
        "def removeEmoji(df):\n",
        "  for i in range(len(df)):\n",
        "    df[\"text\"][i] = emoji_pattern.sub(r\"\", df[\"text\"][i])\n",
        "\n",
        "def tokenize(df):\n",
        "  for i in range(len(df)):\n",
        "    df[\"text\"][i] = indic_tokenize.trivial_tokenize(df[\"text\"][i])\n",
        "\n",
        "def cleanSentences(df):\n",
        "  hindi_stopwords = ['तुम','मेरी','मुझे','क्योंकि','हम','प्रति','अबकी','आगे','माननीय','शहर','बताएं','कौनसी','क्लिक','किसकी','बड़े','मैं','and','रही','आज','लें','आपके','मिलकर','सब','मेरे','जी','श्री','वैसा','आपका','अंदर', 'अत', 'अपना', 'अपनी', 'अपने', 'अभी', 'आदि', 'आप', 'इत्यादि', 'इन', 'इनका', 'इन्हीं', 'इन्हें', 'इन्हों', 'इस', 'इसका', 'इसकी', 'इसके', 'इसमें', 'इसी', 'इसे', 'उन', 'उनका', 'उनकी', 'उनके', 'उनको', 'उन्हीं', 'उन्हें', 'उन्हों', 'उस', 'उसके', 'उसी', 'उसे', 'एक', 'एवं', 'एस', 'ऐसे', 'और', 'कई', 'कर','करता', 'करते', 'करना', 'करने', 'करें', 'कहते', 'कहा', 'का', 'काफ़ी', 'कि', 'कितना', 'किन्हें', 'किन्हों', 'किया', 'किर', 'किस', 'किसी', 'किसे', 'की', 'कुछ', 'कुल', 'के', 'को', 'कोई', 'कौन', 'कौनसा', 'गया', 'घर', 'जब', 'जहाँ', 'जा', 'जितना', 'जिन', 'जिन्हें', 'जिन्हों', 'जिस', 'जिसे', 'जीधर', 'जैसा', 'जैसे', 'जो', 'तक', 'तब', 'तरह', 'तिन', 'तिन्हें', 'तिन्हों', 'तिस', 'तिसे', 'तो', 'था', 'थी', 'थे', 'दबारा', 'दिया', 'दुसरा', 'दूसरे', 'दो', 'द्वारा', 'न', 'नहीं', 'ना', 'निहायत', 'नीचे', 'ने', 'पर', 'पर', 'पहले', 'पूरा', 'पे', 'फिर', 'बनी', 'बही', 'बहुत', 'बाद', 'बाला', 'बिलकुल', 'भी', 'भीतर', 'मगर', 'मानो', 'मे', 'में', 'यदि', 'यह', 'यहाँ', 'यही', 'या', 'यिह', 'ये', 'रखें', 'रहा', 'रहे', 'ऱ्वासा', 'लिए', 'लिये', 'लेकिन', 'व', 'वर्ग', 'वह', 'वह', 'वहाँ', 'वहीं', 'वाले', 'वुह', 'वे', 'वग़ैरह', 'संग', 'सकता', 'सकते', 'सबसे', 'सभी', 'साथ', 'साबुत', 'साभ', 'सारा', 'से', 'सो', 'ही', 'हुआ', 'हुई', 'हुए', 'है', 'हैं', 'हो', 'होता', 'होती', 'होते', 'होना', 'होने', 'अपनि', 'जेसे', 'होति', 'सभि', 'तिंहों', 'इंहों', 'दवारा', 'इसि', 'किंहें', 'थि', 'उंहों', 'ओर', 'जिंहें', 'वहिं', 'अभि', 'बनि', 'हि', 'उंहिं', 'उंहें', 'हें', 'वगेरह', 'एसे', 'रवासा', 'कोन', 'निचे', 'काफि', 'उसि', 'पुरा', 'भितर', 'हे', 'बहि', 'वहां', 'कोइ', 'यहां', 'जिंहों', 'तिंहें', 'किसि', 'कइ', 'यहि', 'इंहिं', 'जिधर', 'इंहें', 'अदि', 'इतयादि', 'हुइ', 'कोनसा', 'इसकि', 'दुसरे', 'जहां', 'अप', 'किंहों', 'उनकि', 'भि', 'वरग', 'हुअ', 'जेसा', 'नहिं']    \n",
        "  punctuations = ['।','/', '`', '+', '?','▁', '(', '$', '@', '[', '_', '!', ',', ':', '^', '|', ']', '=', '%', '&', '.', ')', '(', '#', '*', '', ';', '-', '}','|']\n",
        "  to_be_removed = hindi_stopwords + punctuations\n",
        "  for i in range(len(df)):\n",
        "    df['text'][i]=[ele for ele in df['text'][i] if ele not in (to_be_removed)]\n",
        "\n",
        "def preprocess(df):\n",
        "  removeEmoji(df)\n",
        "  tokenize(df)    \n",
        "  cleanSentences(df)"
      ],
      "metadata": {
        "id": "pl3p9I562yUW"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url_test = \"https://raw.githubusercontent.com/PrynkaSxna/dataset/main/emoHi-test.csv\"\n",
        "df_test = pd.read_csv(url_test)\n",
        "preprocess(df_test)"
      ],
      "metadata": {
        "id": "_9KIiWt6qfGl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url_valid =\"https://raw.githubusercontent.com/PrynkaSxna/dataset/main/emoHi-valid.csv\"\n",
        "df_valid = pd.read_csv(url_valid)\n",
        "preprocess(df_valid)"
      ],
      "metadata": {
        "id": "t65mu6prxYta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url_train = \"https://raw.githubusercontent.com/PrynkaSxna/dataset/main/emoHi-train.csv\"\n",
        "df_train = pd.read_csv(url_train)\n",
        "preprocess(df_train)"
      ],
      "metadata": {
        "id": "yJvoYg80xftJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install inltk\n",
        "!pip uninstall torch\n",
        "!pip install torch==1.3.1+cpu -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "from inltk.inltk import setup\n",
        "setup(\"hi\")"
      ],
      "metadata": {
        "id": "s0jZ1VUoR-Wl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from inltk.inltk import get_embedding_vectors\n",
        "\n",
        "embeddings_test = []\n",
        "for i in range(0, len(df_test[\"text\"])):\n",
        "  embeddings_test.append(get_embedding_vectors(' '.join(df_test[\"text\"][i]), \"hi\"))\n",
        "\n",
        "embeddings_valid = []\n",
        "for i in range(0, len(df_test[\"text\"])):\n",
        "  embeddings_valid.append(get_embedding_vectors(' '.join(df_valid[\"text\"][i]), \"hi\"))\n",
        "\n",
        "embeddings_train = []\n",
        "for i in range(0, len(df_test[\"text\"])):\n",
        "  embeddings_train.append(get_embedding_vectors(' '.join(df_train[\"text\"][i]), \"hi\"))   "
      ],
      "metadata": {
        "id": "FM8VplNfSban"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}