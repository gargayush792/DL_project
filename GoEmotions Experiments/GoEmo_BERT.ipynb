{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('emoHi-train.csv.zip', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('emoHi-test.csv.zip', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = pd.read_csv('emoHi-valid.csv.zip', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['labels'] = train['labels'].str.replace(r'[', '')\n",
    "train['labels'] = train['labels'].str.replace(r']', '')\n",
    "train['labels'] = train['labels'].str.strip()\n",
    "\n",
    "test['labels'] = test['labels'].str.replace(r'[', '')\n",
    "test['labels'] = test['labels'].str.replace(r']', '')\n",
    "test['labels'] = test['labels'].str.strip()\n",
    "\n",
    "val['labels'] = val['labels'].str.replace(r'[', '')\n",
    "val['labels'] = val['labels'].str.replace(r']', '')\n",
    "val['labels'] = val['labels'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['label'] = train['labels'].str.split(' ',expand=True)[0].astype(int)\n",
    "test['label'] = test['labels'].str.split(' ',expand=True)[0].astype(int)\n",
    "val['label'] = val['labels'].str.split(' ',expand=True)[0].astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"admiration\", \"amusement\",\n",
    "                \"anger\", \"annoyance\",\n",
    "                \"approval\", \"caring\",\n",
    "                \"confusion\", \"curiosity\",\n",
    "                \"desire\", \"disappointment\",\n",
    "                \"disapproval\", \"disgust\",\n",
    "                \"embarrassment\", \"excitement\",\n",
    "                \"fear\", \"gratitude\",\n",
    "                \"grief\", \"joy\",\n",
    "                \"love\", \"nervousness\",\n",
    "                \"optimism\", \"pride\",\n",
    "                \"realization\", \"relief\",\n",
    "                \"remorse\", \"sadness\",\n",
    "                \"surprise\", \"neutral\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    from datasets import ClassLabel, Features, Value\n",
    "    from datasets import Dataset\n",
    "    import pandas as pd\n",
    "    emotion_features = Features({'text': Value('string'), 'label': ClassLabel(names=class_labels)})\n",
    "    \n",
    "    train_dataset = Dataset.from_pandas(train, features = emotion_features)\n",
    "    test_dataset = Dataset.from_pandas(test, features = emotion_features)\n",
    "    \n",
    "    print (\"Prepared Train and test data\")\n",
    "    return train_dataset, test_dataset\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"bert-base-multilingual-cased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    from transformers import AutoTokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_tokens():\n",
    "    train_dataset, test_dataset = load_data()\n",
    "    print (\"Train and Test data load successful\")\n",
    "    tokenized_train = train_dataset.map(tokenize_function, batched=True)\n",
    "    tokenized_test = test_dataset.map(tokenize_function, batched=True)\n",
    "    print (\"Train and Test data tokenised\")\n",
    "    \n",
    "    small_train_dataset = tokenized_train.shuffle(seed=42).select(range(1000))\n",
    "    small_eval_dataset = tokenized_test.shuffle(seed=42).select(range(1000))\n",
    "    full_train_dataset = tokenized_train\n",
    "    full_eval_dataset = tokenized_test\n",
    "    \n",
    "    return full_train_dataset, full_eval_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    import numpy as np\n",
    "    from datasets import load_metric\n",
    "    metric = load_metric(\"f1\")\n",
    "\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels, average = 'macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_model():\n",
    "    from transformers import AutoModelForSequenceClassification\n",
    "    from transformers import TrainingArguments, Trainer\n",
    "    \n",
    "    small_train_dataset, small_eval_dataset = prep_tokens()\n",
    "    print (small_train_dataset)\n",
    "    print (\"Tokenised data load successful\")\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(MODEL, num_labels=28)\n",
    "    training_args = TrainingArguments(\"test_trainer\", evaluation_strategy=\"epoch\", logging_strategy=\"epoch\")\n",
    "    print (\"Starting Training\")\n",
    "    trainer = Trainer(model=model, args=training_args, train_dataset=small_train_dataset, eval_dataset=small_eval_dataset)\n",
    "    trainer.train()\n",
    "    trainer = Trainer(model=model, args=training_args, train_dataset=small_train_dataset, eval_dataset=small_eval_dataset, compute_metrics=compute_metrics)\n",
    "    \n",
    "    predictions = trainer.predict(small_eval_dataset)\n",
    "    return predictions[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared Train and test data\n",
      "Train and Test data load successful\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/44 [00:00<?, ?ba/s]\n",
      "Downloading: 100%|██████████| 29.0/29.0 [00:00<00:00, 33.5kB/s]\n",
      "\n",
      "Downloading: 100%|██████████| 625/625 [00:00<00:00, 913kB/s]\n",
      "\n",
      "Downloading: 100%|██████████| 972k/972k [00:00<00:00, 20.6MB/s]\n",
      "\n",
      "Downloading: 100%|██████████| 1.87M/1.87M [00:00<00:00, 26.1MB/s]\n",
      "100%|██████████| 44/44 [00:27<00:00,  1.63ba/s]\n",
      "100%|██████████| 6/6 [00:03<00:00,  1.69ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and Test data tokenised\n",
      "Dataset({\n",
      "    features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "    num_rows: 43410\n",
      "})\n",
      "Tokenised data load successful\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 681M/681M [00:08<00:00, 80.3MB/s]\n",
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/usr/lib/python3.6/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 43410\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16281\n",
      "  3%|▎         | 500/16281 [03:24<1:48:05,  2.43it/s]Saving model checkpoint to test_trainer/checkpoint-500\n",
      "Configuration saved in test_trainer/checkpoint-500/config.json\n",
      "Model weights saved in test_trainer/checkpoint-500/pytorch_model.bin\n",
      "  6%|▌         | 1000/16281 [06:50<1:44:32,  2.44it/s]Saving model checkpoint to test_trainer/checkpoint-1000\n",
      "Configuration saved in test_trainer/checkpoint-1000/config.json\n",
      "Model weights saved in test_trainer/checkpoint-1000/pytorch_model.bin\n",
      "  9%|▉         | 1500/16281 [10:17<1:40:54,  2.44it/s]Saving model checkpoint to test_trainer/checkpoint-1500\n",
      "Configuration saved in test_trainer/checkpoint-1500/config.json\n",
      "Model weights saved in test_trainer/checkpoint-1500/pytorch_model.bin\n",
      " 12%|█▏        | 2000/16281 [13:44<1:37:44,  2.44it/s]Saving model checkpoint to test_trainer/checkpoint-2000\n",
      "Configuration saved in test_trainer/checkpoint-2000/config.json\n",
      "Model weights saved in test_trainer/checkpoint-2000/pytorch_model.bin\n",
      " 15%|█▌        | 2500/16281 [17:11<1:34:09,  2.44it/s]Saving model checkpoint to test_trainer/checkpoint-2500\n",
      "Configuration saved in test_trainer/checkpoint-2500/config.json\n",
      "Model weights saved in test_trainer/checkpoint-2500/pytorch_model.bin\n",
      " 18%|█▊        | 3000/16281 [20:38<1:30:54,  2.43it/s]Saving model checkpoint to test_trainer/checkpoint-3000\n",
      "Configuration saved in test_trainer/checkpoint-3000/config.json\n",
      "Model weights saved in test_trainer/checkpoint-3000/pytorch_model.bin\n",
      " 21%|██▏       | 3500/16281 [24:04<1:27:30,  2.43it/s]Saving model checkpoint to test_trainer/checkpoint-3500\n",
      "Configuration saved in test_trainer/checkpoint-3500/config.json\n",
      "Model weights saved in test_trainer/checkpoint-3500/pytorch_model.bin\n",
      " 25%|██▍       | 4000/16281 [27:31<1:24:03,  2.44it/s]Saving model checkpoint to test_trainer/checkpoint-4000\n",
      "Configuration saved in test_trainer/checkpoint-4000/config.json\n",
      "Model weights saved in test_trainer/checkpoint-4000/pytorch_model.bin\n",
      " 28%|██▊       | 4500/16281 [30:58<1:20:25,  2.44it/s]Saving model checkpoint to test_trainer/checkpoint-4500\n",
      "Configuration saved in test_trainer/checkpoint-4500/config.json\n",
      "Model weights saved in test_trainer/checkpoint-4500/pytorch_model.bin\n",
      " 29%|██▊       | 4655/16281 [32:04<1:19:29,  2.44it/s]"
     ]
    }
   ],
   "source": [
    "a = prep_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.3704215 ,  0.7323609 ,  0.3023718 , ..., -0.20485705,\n",
       "        -0.48639953,  2.4607034 ],\n",
       "       [ 1.3704216 ,  0.7323609 ,  0.3023718 , ..., -0.20485717,\n",
       "        -0.48639953,  2.4607034 ],\n",
       "       [ 1.3704215 ,  0.73236084,  0.30237174, ..., -0.20485708,\n",
       "        -0.4863995 ,  2.4607036 ],\n",
       "       ...,\n",
       "       [ 1.3704216 ,  0.7323609 ,  0.30237183, ..., -0.2048571 ,\n",
       "        -0.48639956,  2.4607034 ],\n",
       "       [ 1.3704216 ,  0.7323609 ,  0.30237183, ..., -0.2048571 ,\n",
       "        -0.4863995 ,  2.4607034 ],\n",
       "       [ 1.3704216 ,  0.732361  ,  0.30237183, ..., -0.20485714,\n",
       "        -0.4863995 ,  2.4607034 ]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax_predictions = softmax(a, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "goemotions_predictions = pd.DataFrame(softmax_predictions, columns = class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "goemotions_predictions['goemotions_class'] = goemotions_predictions.idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>goemotions_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.103993</td>\n",
       "      <td>0.054941</td>\n",
       "      <td>0.03574</td>\n",
       "      <td>0.048363</td>\n",
       "      <td>0.061836</td>\n",
       "      <td>0.022447</td>\n",
       "      <td>0.015066</td>\n",
       "      <td>0.009841</td>\n",
       "      <td>0.013797</td>\n",
       "      <td>0.024816</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002662</td>\n",
       "      <td>0.022147</td>\n",
       "      <td>0.001422</td>\n",
       "      <td>0.017476</td>\n",
       "      <td>0.002229</td>\n",
       "      <td>0.00934</td>\n",
       "      <td>0.021521</td>\n",
       "      <td>0.01624</td>\n",
       "      <td>0.309390</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.103993</td>\n",
       "      <td>0.054941</td>\n",
       "      <td>0.03574</td>\n",
       "      <td>0.048363</td>\n",
       "      <td>0.061836</td>\n",
       "      <td>0.022447</td>\n",
       "      <td>0.015066</td>\n",
       "      <td>0.009841</td>\n",
       "      <td>0.013797</td>\n",
       "      <td>0.024816</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002662</td>\n",
       "      <td>0.022147</td>\n",
       "      <td>0.001422</td>\n",
       "      <td>0.017476</td>\n",
       "      <td>0.002229</td>\n",
       "      <td>0.00934</td>\n",
       "      <td>0.021521</td>\n",
       "      <td>0.01624</td>\n",
       "      <td>0.309390</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.103993</td>\n",
       "      <td>0.054941</td>\n",
       "      <td>0.03574</td>\n",
       "      <td>0.048363</td>\n",
       "      <td>0.061836</td>\n",
       "      <td>0.022447</td>\n",
       "      <td>0.015066</td>\n",
       "      <td>0.009841</td>\n",
       "      <td>0.013797</td>\n",
       "      <td>0.024816</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002662</td>\n",
       "      <td>0.022147</td>\n",
       "      <td>0.001422</td>\n",
       "      <td>0.017476</td>\n",
       "      <td>0.002229</td>\n",
       "      <td>0.00934</td>\n",
       "      <td>0.021521</td>\n",
       "      <td>0.01624</td>\n",
       "      <td>0.309391</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.103993</td>\n",
       "      <td>0.054941</td>\n",
       "      <td>0.03574</td>\n",
       "      <td>0.048364</td>\n",
       "      <td>0.061836</td>\n",
       "      <td>0.022447</td>\n",
       "      <td>0.015066</td>\n",
       "      <td>0.009841</td>\n",
       "      <td>0.013797</td>\n",
       "      <td>0.024816</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002662</td>\n",
       "      <td>0.022147</td>\n",
       "      <td>0.001422</td>\n",
       "      <td>0.017476</td>\n",
       "      <td>0.002229</td>\n",
       "      <td>0.00934</td>\n",
       "      <td>0.021521</td>\n",
       "      <td>0.01624</td>\n",
       "      <td>0.309390</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.103993</td>\n",
       "      <td>0.054941</td>\n",
       "      <td>0.03574</td>\n",
       "      <td>0.048363</td>\n",
       "      <td>0.061836</td>\n",
       "      <td>0.022447</td>\n",
       "      <td>0.015066</td>\n",
       "      <td>0.009841</td>\n",
       "      <td>0.013797</td>\n",
       "      <td>0.024816</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002662</td>\n",
       "      <td>0.022147</td>\n",
       "      <td>0.001422</td>\n",
       "      <td>0.017476</td>\n",
       "      <td>0.002229</td>\n",
       "      <td>0.00934</td>\n",
       "      <td>0.021521</td>\n",
       "      <td>0.01624</td>\n",
       "      <td>0.309390</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5422</th>\n",
       "      <td>0.103993</td>\n",
       "      <td>0.054941</td>\n",
       "      <td>0.03574</td>\n",
       "      <td>0.048364</td>\n",
       "      <td>0.061836</td>\n",
       "      <td>0.022447</td>\n",
       "      <td>0.015066</td>\n",
       "      <td>0.009841</td>\n",
       "      <td>0.013797</td>\n",
       "      <td>0.024816</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002662</td>\n",
       "      <td>0.022147</td>\n",
       "      <td>0.001422</td>\n",
       "      <td>0.017476</td>\n",
       "      <td>0.002229</td>\n",
       "      <td>0.00934</td>\n",
       "      <td>0.021521</td>\n",
       "      <td>0.01624</td>\n",
       "      <td>0.309390</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5423</th>\n",
       "      <td>0.103993</td>\n",
       "      <td>0.054941</td>\n",
       "      <td>0.03574</td>\n",
       "      <td>0.048363</td>\n",
       "      <td>0.061836</td>\n",
       "      <td>0.022447</td>\n",
       "      <td>0.015066</td>\n",
       "      <td>0.009841</td>\n",
       "      <td>0.013797</td>\n",
       "      <td>0.024816</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002662</td>\n",
       "      <td>0.022147</td>\n",
       "      <td>0.001422</td>\n",
       "      <td>0.017476</td>\n",
       "      <td>0.002229</td>\n",
       "      <td>0.00934</td>\n",
       "      <td>0.021521</td>\n",
       "      <td>0.01624</td>\n",
       "      <td>0.309391</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5424</th>\n",
       "      <td>0.103993</td>\n",
       "      <td>0.054941</td>\n",
       "      <td>0.03574</td>\n",
       "      <td>0.048363</td>\n",
       "      <td>0.061836</td>\n",
       "      <td>0.022447</td>\n",
       "      <td>0.015066</td>\n",
       "      <td>0.009841</td>\n",
       "      <td>0.013797</td>\n",
       "      <td>0.024816</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002662</td>\n",
       "      <td>0.022147</td>\n",
       "      <td>0.001422</td>\n",
       "      <td>0.017476</td>\n",
       "      <td>0.002229</td>\n",
       "      <td>0.00934</td>\n",
       "      <td>0.021521</td>\n",
       "      <td>0.01624</td>\n",
       "      <td>0.309390</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5425</th>\n",
       "      <td>0.103993</td>\n",
       "      <td>0.054941</td>\n",
       "      <td>0.03574</td>\n",
       "      <td>0.048364</td>\n",
       "      <td>0.061836</td>\n",
       "      <td>0.022447</td>\n",
       "      <td>0.015066</td>\n",
       "      <td>0.009841</td>\n",
       "      <td>0.013797</td>\n",
       "      <td>0.024816</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002662</td>\n",
       "      <td>0.022147</td>\n",
       "      <td>0.001422</td>\n",
       "      <td>0.017476</td>\n",
       "      <td>0.002229</td>\n",
       "      <td>0.00934</td>\n",
       "      <td>0.021521</td>\n",
       "      <td>0.01624</td>\n",
       "      <td>0.309390</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5426</th>\n",
       "      <td>0.103993</td>\n",
       "      <td>0.054941</td>\n",
       "      <td>0.03574</td>\n",
       "      <td>0.048364</td>\n",
       "      <td>0.061836</td>\n",
       "      <td>0.022447</td>\n",
       "      <td>0.015066</td>\n",
       "      <td>0.009841</td>\n",
       "      <td>0.013797</td>\n",
       "      <td>0.024816</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002662</td>\n",
       "      <td>0.022147</td>\n",
       "      <td>0.001422</td>\n",
       "      <td>0.017476</td>\n",
       "      <td>0.002229</td>\n",
       "      <td>0.00934</td>\n",
       "      <td>0.021521</td>\n",
       "      <td>0.01624</td>\n",
       "      <td>0.309390</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5427 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1        2         3         4         5         6  \\\n",
       "0     0.103993  0.054941  0.03574  0.048363  0.061836  0.022447  0.015066   \n",
       "1     0.103993  0.054941  0.03574  0.048363  0.061836  0.022447  0.015066   \n",
       "2     0.103993  0.054941  0.03574  0.048363  0.061836  0.022447  0.015066   \n",
       "3     0.103993  0.054941  0.03574  0.048364  0.061836  0.022447  0.015066   \n",
       "4     0.103993  0.054941  0.03574  0.048363  0.061836  0.022447  0.015066   \n",
       "...        ...       ...      ...       ...       ...       ...       ...   \n",
       "5422  0.103993  0.054941  0.03574  0.048364  0.061836  0.022447  0.015066   \n",
       "5423  0.103993  0.054941  0.03574  0.048363  0.061836  0.022447  0.015066   \n",
       "5424  0.103993  0.054941  0.03574  0.048363  0.061836  0.022447  0.015066   \n",
       "5425  0.103993  0.054941  0.03574  0.048364  0.061836  0.022447  0.015066   \n",
       "5426  0.103993  0.054941  0.03574  0.048364  0.061836  0.022447  0.015066   \n",
       "\n",
       "             7         8         9  ...        19        20        21  \\\n",
       "0     0.009841  0.013797  0.024816  ...  0.002662  0.022147  0.001422   \n",
       "1     0.009841  0.013797  0.024816  ...  0.002662  0.022147  0.001422   \n",
       "2     0.009841  0.013797  0.024816  ...  0.002662  0.022147  0.001422   \n",
       "3     0.009841  0.013797  0.024816  ...  0.002662  0.022147  0.001422   \n",
       "4     0.009841  0.013797  0.024816  ...  0.002662  0.022147  0.001422   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "5422  0.009841  0.013797  0.024816  ...  0.002662  0.022147  0.001422   \n",
       "5423  0.009841  0.013797  0.024816  ...  0.002662  0.022147  0.001422   \n",
       "5424  0.009841  0.013797  0.024816  ...  0.002662  0.022147  0.001422   \n",
       "5425  0.009841  0.013797  0.024816  ...  0.002662  0.022147  0.001422   \n",
       "5426  0.009841  0.013797  0.024816  ...  0.002662  0.022147  0.001422   \n",
       "\n",
       "            22        23       24        25       26        27  \\\n",
       "0     0.017476  0.002229  0.00934  0.021521  0.01624  0.309390   \n",
       "1     0.017476  0.002229  0.00934  0.021521  0.01624  0.309390   \n",
       "2     0.017476  0.002229  0.00934  0.021521  0.01624  0.309391   \n",
       "3     0.017476  0.002229  0.00934  0.021521  0.01624  0.309390   \n",
       "4     0.017476  0.002229  0.00934  0.021521  0.01624  0.309390   \n",
       "...        ...       ...      ...       ...      ...       ...   \n",
       "5422  0.017476  0.002229  0.00934  0.021521  0.01624  0.309390   \n",
       "5423  0.017476  0.002229  0.00934  0.021521  0.01624  0.309391   \n",
       "5424  0.017476  0.002229  0.00934  0.021521  0.01624  0.309390   \n",
       "5425  0.017476  0.002229  0.00934  0.021521  0.01624  0.309390   \n",
       "5426  0.017476  0.002229  0.00934  0.021521  0.01624  0.309390   \n",
       "\n",
       "      goemotions_class  \n",
       "0                   27  \n",
       "1                   27  \n",
       "2                   27  \n",
       "3                   27  \n",
       "4                   27  \n",
       "...                ...  \n",
       "5422                27  \n",
       "5423                27  \n",
       "5424                27  \n",
       "5425                27  \n",
       "5426                27  \n",
       "\n",
       "[5427 rows x 29 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goemotions_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.merge(test, goemotions_predictions, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>labels</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>...</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>goemotions_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eecwqtt</td>\n",
       "      <td>25</td>\n",
       "      <td>मुझे आपकी स्थिति के लिए वास्तव में खेद है :( ह...</td>\n",
       "      <td>25</td>\n",
       "      <td>0.103993</td>\n",
       "      <td>0.054941</td>\n",
       "      <td>0.03574</td>\n",
       "      <td>0.048363</td>\n",
       "      <td>0.061836</td>\n",
       "      <td>0.022447</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002662</td>\n",
       "      <td>0.022147</td>\n",
       "      <td>0.001422</td>\n",
       "      <td>0.017476</td>\n",
       "      <td>0.002229</td>\n",
       "      <td>0.00934</td>\n",
       "      <td>0.021521</td>\n",
       "      <td>0.01624</td>\n",
       "      <td>0.309390</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ed5f85d</td>\n",
       "      <td>0</td>\n",
       "      <td>यह अद्भुत है क्योंकि यह भयानक है। पर साथ नहीं।</td>\n",
       "      <td>0</td>\n",
       "      <td>0.103993</td>\n",
       "      <td>0.054941</td>\n",
       "      <td>0.03574</td>\n",
       "      <td>0.048363</td>\n",
       "      <td>0.061836</td>\n",
       "      <td>0.022447</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002662</td>\n",
       "      <td>0.022147</td>\n",
       "      <td>0.001422</td>\n",
       "      <td>0.017476</td>\n",
       "      <td>0.002229</td>\n",
       "      <td>0.00934</td>\n",
       "      <td>0.021521</td>\n",
       "      <td>0.01624</td>\n",
       "      <td>0.309390</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>een27c3</td>\n",
       "      <td>13</td>\n",
       "      <td>किंग्स फैन यहाँ, आप लोगों को शुभकामनाएँ! देखने...</td>\n",
       "      <td>13</td>\n",
       "      <td>0.103993</td>\n",
       "      <td>0.054941</td>\n",
       "      <td>0.03574</td>\n",
       "      <td>0.048363</td>\n",
       "      <td>0.061836</td>\n",
       "      <td>0.022447</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002662</td>\n",
       "      <td>0.022147</td>\n",
       "      <td>0.001422</td>\n",
       "      <td>0.017476</td>\n",
       "      <td>0.002229</td>\n",
       "      <td>0.00934</td>\n",
       "      <td>0.021521</td>\n",
       "      <td>0.01624</td>\n",
       "      <td>0.309391</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eelgwd1</td>\n",
       "      <td>15</td>\n",
       "      <td>मुझे यह नहीं पता था, आज मुझे कुछ सिखाने के लिए...</td>\n",
       "      <td>15</td>\n",
       "      <td>0.103993</td>\n",
       "      <td>0.054941</td>\n",
       "      <td>0.03574</td>\n",
       "      <td>0.048364</td>\n",
       "      <td>0.061836</td>\n",
       "      <td>0.022447</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002662</td>\n",
       "      <td>0.022147</td>\n",
       "      <td>0.001422</td>\n",
       "      <td>0.017476</td>\n",
       "      <td>0.002229</td>\n",
       "      <td>0.00934</td>\n",
       "      <td>0.021521</td>\n",
       "      <td>0.01624</td>\n",
       "      <td>0.309390</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eem5uti</td>\n",
       "      <td>27</td>\n",
       "      <td>वे हज़ारों वर्षों तक भूतिया धरती से ऊब चुके थे...</td>\n",
       "      <td>27</td>\n",
       "      <td>0.103993</td>\n",
       "      <td>0.054941</td>\n",
       "      <td>0.03574</td>\n",
       "      <td>0.048363</td>\n",
       "      <td>0.061836</td>\n",
       "      <td>0.022447</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002662</td>\n",
       "      <td>0.022147</td>\n",
       "      <td>0.001422</td>\n",
       "      <td>0.017476</td>\n",
       "      <td>0.002229</td>\n",
       "      <td>0.00934</td>\n",
       "      <td>0.021521</td>\n",
       "      <td>0.01624</td>\n",
       "      <td>0.309390</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5422</th>\n",
       "      <td>efeeasc</td>\n",
       "      <td>15</td>\n",
       "      <td>धन्यवाद। मुझे अस्पताल में भर्ती होने के बाद भी...</td>\n",
       "      <td>15</td>\n",
       "      <td>0.103993</td>\n",
       "      <td>0.054941</td>\n",
       "      <td>0.03574</td>\n",
       "      <td>0.048364</td>\n",
       "      <td>0.061836</td>\n",
       "      <td>0.022447</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002662</td>\n",
       "      <td>0.022147</td>\n",
       "      <td>0.001422</td>\n",
       "      <td>0.017476</td>\n",
       "      <td>0.002229</td>\n",
       "      <td>0.00934</td>\n",
       "      <td>0.021521</td>\n",
       "      <td>0.01624</td>\n",
       "      <td>0.309390</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5423</th>\n",
       "      <td>ef9c7s3</td>\n",
       "      <td>4</td>\n",
       "      <td>अच्छा यह समझ में आता है।</td>\n",
       "      <td>4</td>\n",
       "      <td>0.103993</td>\n",
       "      <td>0.054941</td>\n",
       "      <td>0.03574</td>\n",
       "      <td>0.048363</td>\n",
       "      <td>0.061836</td>\n",
       "      <td>0.022447</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002662</td>\n",
       "      <td>0.022147</td>\n",
       "      <td>0.001422</td>\n",
       "      <td>0.017476</td>\n",
       "      <td>0.002229</td>\n",
       "      <td>0.00934</td>\n",
       "      <td>0.021521</td>\n",
       "      <td>0.01624</td>\n",
       "      <td>0.309391</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5424</th>\n",
       "      <td>efbiugo</td>\n",
       "      <td>27</td>\n",
       "      <td>डैडी मुद्दे [NAME]</td>\n",
       "      <td>27</td>\n",
       "      <td>0.103993</td>\n",
       "      <td>0.054941</td>\n",
       "      <td>0.03574</td>\n",
       "      <td>0.048363</td>\n",
       "      <td>0.061836</td>\n",
       "      <td>0.022447</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002662</td>\n",
       "      <td>0.022147</td>\n",
       "      <td>0.001422</td>\n",
       "      <td>0.017476</td>\n",
       "      <td>0.002229</td>\n",
       "      <td>0.00934</td>\n",
       "      <td>0.021521</td>\n",
       "      <td>0.01624</td>\n",
       "      <td>0.309390</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5425</th>\n",
       "      <td>efbvgp9</td>\n",
       "      <td>0</td>\n",
       "      <td>बहुत खुशी है कि मैंने कुछ महीने पहले उस सब्रेड...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.103993</td>\n",
       "      <td>0.054941</td>\n",
       "      <td>0.03574</td>\n",
       "      <td>0.048364</td>\n",
       "      <td>0.061836</td>\n",
       "      <td>0.022447</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002662</td>\n",
       "      <td>0.022147</td>\n",
       "      <td>0.001422</td>\n",
       "      <td>0.017476</td>\n",
       "      <td>0.002229</td>\n",
       "      <td>0.00934</td>\n",
       "      <td>0.021521</td>\n",
       "      <td>0.01624</td>\n",
       "      <td>0.309390</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5426</th>\n",
       "      <td>edtjpv6</td>\n",
       "      <td>27</td>\n",
       "      <td>जब मेरे बच्चे छोटे थे तब कई बार \"एल्मो इन ग्रौ...</td>\n",
       "      <td>27</td>\n",
       "      <td>0.103993</td>\n",
       "      <td>0.054941</td>\n",
       "      <td>0.03574</td>\n",
       "      <td>0.048364</td>\n",
       "      <td>0.061836</td>\n",
       "      <td>0.022447</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002662</td>\n",
       "      <td>0.022147</td>\n",
       "      <td>0.001422</td>\n",
       "      <td>0.017476</td>\n",
       "      <td>0.002229</td>\n",
       "      <td>0.00934</td>\n",
       "      <td>0.021521</td>\n",
       "      <td>0.01624</td>\n",
       "      <td>0.309390</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5427 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id labels                                               text  \\\n",
       "0     eecwqtt     25  मुझे आपकी स्थिति के लिए वास्तव में खेद है :( ह...   \n",
       "1     ed5f85d      0     यह अद्भुत है क्योंकि यह भयानक है। पर साथ नहीं।   \n",
       "2     een27c3     13  किंग्स फैन यहाँ, आप लोगों को शुभकामनाएँ! देखने...   \n",
       "3     eelgwd1     15  मुझे यह नहीं पता था, आज मुझे कुछ सिखाने के लिए...   \n",
       "4     eem5uti     27  वे हज़ारों वर्षों तक भूतिया धरती से ऊब चुके थे...   \n",
       "...       ...    ...                                                ...   \n",
       "5422  efeeasc     15  धन्यवाद। मुझे अस्पताल में भर्ती होने के बाद भी...   \n",
       "5423  ef9c7s3      4                           अच्छा यह समझ में आता है।   \n",
       "5424  efbiugo     27                                 डैडी मुद्दे [NAME]   \n",
       "5425  efbvgp9      0  बहुत खुशी है कि मैंने कुछ महीने पहले उस सब्रेड...   \n",
       "5426  edtjpv6     27  जब मेरे बच्चे छोटे थे तब कई बार \"एल्मो इन ग्रौ...   \n",
       "\n",
       "      label         0         1        2         3         4         5  ...  \\\n",
       "0        25  0.103993  0.054941  0.03574  0.048363  0.061836  0.022447  ...   \n",
       "1         0  0.103993  0.054941  0.03574  0.048363  0.061836  0.022447  ...   \n",
       "2        13  0.103993  0.054941  0.03574  0.048363  0.061836  0.022447  ...   \n",
       "3        15  0.103993  0.054941  0.03574  0.048364  0.061836  0.022447  ...   \n",
       "4        27  0.103993  0.054941  0.03574  0.048363  0.061836  0.022447  ...   \n",
       "...     ...       ...       ...      ...       ...       ...       ...  ...   \n",
       "5422     15  0.103993  0.054941  0.03574  0.048364  0.061836  0.022447  ...   \n",
       "5423      4  0.103993  0.054941  0.03574  0.048363  0.061836  0.022447  ...   \n",
       "5424     27  0.103993  0.054941  0.03574  0.048363  0.061836  0.022447  ...   \n",
       "5425      0  0.103993  0.054941  0.03574  0.048364  0.061836  0.022447  ...   \n",
       "5426     27  0.103993  0.054941  0.03574  0.048364  0.061836  0.022447  ...   \n",
       "\n",
       "            19        20        21        22        23       24        25  \\\n",
       "0     0.002662  0.022147  0.001422  0.017476  0.002229  0.00934  0.021521   \n",
       "1     0.002662  0.022147  0.001422  0.017476  0.002229  0.00934  0.021521   \n",
       "2     0.002662  0.022147  0.001422  0.017476  0.002229  0.00934  0.021521   \n",
       "3     0.002662  0.022147  0.001422  0.017476  0.002229  0.00934  0.021521   \n",
       "4     0.002662  0.022147  0.001422  0.017476  0.002229  0.00934  0.021521   \n",
       "...        ...       ...       ...       ...       ...      ...       ...   \n",
       "5422  0.002662  0.022147  0.001422  0.017476  0.002229  0.00934  0.021521   \n",
       "5423  0.002662  0.022147  0.001422  0.017476  0.002229  0.00934  0.021521   \n",
       "5424  0.002662  0.022147  0.001422  0.017476  0.002229  0.00934  0.021521   \n",
       "5425  0.002662  0.022147  0.001422  0.017476  0.002229  0.00934  0.021521   \n",
       "5426  0.002662  0.022147  0.001422  0.017476  0.002229  0.00934  0.021521   \n",
       "\n",
       "           26        27  goemotions_class  \n",
       "0     0.01624  0.309390                27  \n",
       "1     0.01624  0.309390                27  \n",
       "2     0.01624  0.309391                27  \n",
       "3     0.01624  0.309390                27  \n",
       "4     0.01624  0.309390                27  \n",
       "...       ...       ...               ...  \n",
       "5422  0.01624  0.309390                27  \n",
       "5423  0.01624  0.309391                27  \n",
       "5424  0.01624  0.309390                27  \n",
       "5425  0.01624  0.309390                27  \n",
       "5426  0.01624  0.309390                27  \n",
       "\n",
       "[5427 rows x 33 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27    4858\n",
       "7      569\n",
       "Name: goemotions_class, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['goemotions_class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dsw/snapshots/snapshot_dsw_default_jupyter/python3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       504\n",
      "           1       0.00      0.00      0.00       252\n",
      "           2       0.00      0.00      0.00       197\n",
      "           3       0.00      0.00      0.00       286\n",
      "           4       0.00      0.00      0.00       318\n",
      "           5       0.00      0.00      0.00       114\n",
      "           6       0.00      0.00      0.00       139\n",
      "           7       0.34      0.84      0.49       233\n",
      "           8       0.00      0.00      0.00        74\n",
      "           9       0.00      0.00      0.00       127\n",
      "          10       0.00      0.00      0.00       220\n",
      "          11       0.00      0.00      0.00        84\n",
      "          12       0.00      0.00      0.00        30\n",
      "          13       0.00      0.00      0.00        84\n",
      "          14       0.00      0.00      0.00        74\n",
      "          15       0.00      0.00      0.00       288\n",
      "          16       0.00      0.00      0.00         6\n",
      "          17       0.00      0.00      0.00       116\n",
      "          18       0.00      0.00      0.00       169\n",
      "          19       0.00      0.00      0.00        16\n",
      "          20       0.00      0.00      0.00       120\n",
      "          21       0.00      0.00      0.00         8\n",
      "          22       0.00      0.00      0.00       109\n",
      "          23       0.00      0.00      0.00         7\n",
      "          24       0.00      0.00      0.00        46\n",
      "          25       0.00      0.00      0.00       108\n",
      "          26       0.00      0.00      0.00        92\n",
      "          27       0.30      0.91      0.45      1606\n",
      "\n",
      "   micro avg       0.31      0.31      0.31      5427\n",
      "   macro avg       0.02      0.06      0.03      5427\n",
      "weighted avg       0.10      0.31      0.15      5427\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(results['label'], results['goemotions_class']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (General DS)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
